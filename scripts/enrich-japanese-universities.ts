#!/usr/bin/env node

/**
 * æ—¥æœ¬ã®å¤§å­¦ï¼ˆcountry_code = 'JP'ï¼‰ã«æ—¥æœ¬èªåã‚’ä»˜ä¸ã™ã‚‹ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
 * - DB å´ã® name_en ã‚’æ­£è¦åŒ–ã—ã¦ normalized_name ã«ä¿å­˜ï¼ˆæœªä¿å­˜ã®å ´åˆï¼‰
 * - æ–‡ç§‘çœ(MEXT)ãƒ‡ãƒ¼ã‚¿ã®è‹±èªåã‚’åŒã˜æ­£è¦åŒ–é–¢æ•°ã§æ­£è¦åŒ–
 * - æ­£è¦åŒ–åã§ã®å®Œå…¨ä¸€è‡´ã€æ¬¡ã«Jaro-Winkleré¡ä¼¼åº¦ã§ãƒãƒƒãƒãƒ³ã‚°
 */

import { config } from 'dotenv'
import { resolve } from 'path'
import { readFileSync } from 'fs'
import { createClient } from '@supabase/supabase-js'
import { normalizeUniversityName } from '../src/lib/university-normalizer'
import jaroWinkler from 'jaro-winkler'

config({ path: resolve(process.cwd(), '.env.local') })

const supabaseUrl = process.env.NEXT_PUBLIC_SUPABASE_URL
const supabaseServiceKey = process.env.SUPABASE_SERVICE_ROLE_KEY || process.env.NEXT_PUBLIC_SUPABASE_ANON_KEY
const mextCsvUrl = process.env.MEXT_CSV_URL || ''

if (!supabaseUrl || !supabaseServiceKey) {
  console.error('âŒ ã‚¨ãƒ©ãƒ¼: Supabaseç’°å¢ƒå¤‰æ•°ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“')
  process.exit(1)
}

const supabase = createClient(supabaseUrl, supabaseServiceKey)

type UnivRow = {
  id: string
  name_en: string
  name_ja: string | null
  normalized_name: string | null
  country_code: string
}

type MextEntry = {
  en: string
  ja: string
}

function parseCsv(content: string): MextEntry[] {
  const lines = content.split(/\r?\n/).filter(l => l.trim().length > 0)
  // æœŸå¾…ã‚«ãƒ©ãƒ : english_name,japanese_name
  const header = lines[0].split(',').map(h => h.trim().toLowerCase())
  const enIdx = header.findIndex(h => /english/i.test(h) || h === 'en' || /name_en/i.test(h))
  const jaIdx = header.findIndex(h => /japanese/i.test(h) || h === 'ja' || /name_ja/i.test(h))
  const entries: MextEntry[] = []
  for (let i = 1; i < lines.length; i++) {
    const cols = lines[i].split(',').map(c => c.trim().replace(/^"|"$/g, ''))
    const en = cols[enIdx] || ''
    const ja = cols[jaIdx] || ''
    if (en && ja) {
      entries.push({ en, ja })
    }
  }
  return entries
}

async function loadMextMapping(): Promise<Map<string, string>> {
  // 1) ç’°å¢ƒå¤‰æ•°ã§CSV URLãŒæŒ‡å®šã•ã‚Œã¦ã„ã‚Œã°å„ªå…ˆ
  if (mextCsvUrl) {
    try {
      const res = await fetch(mextCsvUrl)
      if (res.ok) {
        const text = await res.text()
        const entries = parseCsv(text)
        const map = new Map<string, string>()
        for (const e of entries) {
          const key = normalizeUniversityName(e.en)
          if (key) map.set(key, e.ja)
        }
        if (map.size > 0) return map
      } else {
        console.warn(`âš ï¸ MEXT CSV å–å¾—å¤±æ•—: ${res.status} ${res.statusText}`)
      }
    } catch (e: any) {
      console.warn('âš ï¸ MEXT CSV èª­è¾¼ã‚¨ãƒ©ãƒ¼:', e.message)
    }
  }
  // 2) ãƒ­ãƒ¼ã‚«ãƒ«ã®æ‰‹å‹•ãƒãƒƒãƒ”ãƒ³ã‚°ã‚’ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
  try {
    const localJsonPath = resolve(process.cwd(), 'data/japanese-university-names.json')
    const raw = readFileSync(localJsonPath, 'utf-8')
    const obj = JSON.parse(raw) as Record<string, string>
    const map = new Map<string, string>()
    for (const [en, ja] of Object.entries(obj)) {
      const key = normalizeUniversityName(en)
      if (key) map.set(key, ja)
    }
    return map
  } catch {
    console.warn('âš ï¸ ãƒ­ãƒ¼ã‚«ãƒ«ã®æ‰‹å‹•ãƒãƒƒãƒ”ãƒ³ã‚°ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸï¼ˆdata/japanese-university-names.jsonï¼‰')
  }
  return new Map<string, string>()
}

async function main() {
  console.log('ğŸš€ æ—¥æœ¬èªåä»˜ä¸ã‚¹ã‚¯ãƒªãƒ—ãƒˆé–‹å§‹')

  const mapping = await loadMextMapping()
  console.log(`ğŸ“š MEXT/ãƒ­ãƒ¼ã‚«ãƒ«ãƒãƒƒãƒ”ãƒ³ã‚°ä»¶æ•°: ${mapping.size}`)

  const batchSize = 200
  let offset = 0
  let totalMatched = 0
  let totalUpdated = 0
  let totalSkipped = 0

  while (true) {
    const { data, error } = await supabase
      .from('universities')
      .select('id, name_en, name_ja, normalized_name, country_code')
      .eq('country_code', 'JP')
      .is('name_ja', null)
      .range(offset, offset + batchSize - 1)

    if (error) {
      console.error('âŒ å–å¾—ã‚¨ãƒ©ãƒ¼:', error.message)
      break
    }

    const rows = (data || []) as UnivRow[]
    if (rows.length === 0) break

    console.log(`ğŸ“¦ ãƒãƒƒãƒå–å¾—: ${offset} - ${offset + rows.length - 1}`)

    for (const row of rows) {
      const normalized = row.normalized_name || normalizeUniversityName(row.name_en)
      if (!normalized) {
        totalSkipped++
        continue
      }
      // normalized_name ã‚’ä¿å­˜ï¼ˆæœªè¨­å®šã®å ´åˆï¼‰
      if (!row.normalized_name) {
        await supabase
          .from('universities')
          .update({ normalized_name: normalized })
          .eq('id', row.id)
      }

      // 1) æ­£è¦åŒ–åã§å®Œå…¨ä¸€è‡´
      const exactJa = mapping.get(normalized)
      if (exactJa) {
        const { error: upErr } = await supabase
          .from('universities')
          .update({ name_ja: exactJa, updated_at: new Date().toISOString() })
          .eq('id', row.id)
        if (!upErr) {
          totalUpdated++
          totalMatched++
          continue
        }
      }

      // 2) é¡ä¼¼åº¦ï¼ˆJaro-Winklerï¼‰
      let bestScore = 0
      let bestJa = ''
      mapping.forEach((ja, k) => {
        const score = jaroWinkler(normalized, k)
        if (score > bestScore) {
          bestScore = score
          bestJa = ja
        }
      })
      if (bestScore >= 0.85 && bestJa) {
        const { error: upErr2 } = await supabase
          .from('universities')
          .update({ name_ja: bestJa, updated_at: new Date().toISOString() })
          .eq('id', row.id)
        if (!upErr2) {
          totalUpdated++
          totalMatched++
        } else {
          totalSkipped++
        }
      } else {
        totalSkipped++
      }
    }

    offset += rows.length
    if (rows.length < batchSize) break
  }

  console.log('\nğŸ“Š å‡¦ç†çµæœ')
  console.log(`  ãƒãƒƒãƒ: ${totalMatched}ä»¶`)
  console.log(`  æ›´æ–°: ${totalUpdated}ä»¶`)
  console.log(`  ã‚¹ã‚­ãƒƒãƒ—: ${totalSkipped}ä»¶`)
  console.log('âœ¨ å®Œäº†')
}

main().catch(err => {
  console.error('âŒ äºˆæœŸã›ã¬ã‚¨ãƒ©ãƒ¼:', err)
  process.exit(1)
})


